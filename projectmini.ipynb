{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1168V0SQ9wRdPs-fa4QGe5nWLQ-bSJeBS",
      "authorship_tag": "ABX9TyO1IKG7PGhwMMKqnJjDK9ks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bandinaresh01/sepecific_domain_chat_bot/blob/main/projectmini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEt3p5wxtRpq",
        "outputId": "67507d44-bbb4-4f2c-f4e0-035256d3f519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install flask google-generativeai faiss-cpu sentence-transformers python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 📚 ENHANCED DOCUMENT Q&A SYSTEM\n",
        "# ======================\n",
        "\n",
        "# @title 🛠️ SETUP (Run this first!)\n",
        "!pip install -q google-generativeai faiss-cpu sentence-transformers ipywidgets\n",
        "print(\"✅ Packages installed successfully!\")\n",
        "\n",
        "# @title 🔑 STEP 1: Configure API\n",
        "import google.generativeai as genai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Your configuration\n",
        "genai.configure(api_key=\"AIzaSyBNOxE0ia-roj-IfrFWyPQHE1T6-PSI37M\")\n",
        "VECTOR_DB_PATH = \"/content/drive/MyDrive/Educational_PDF/vectorstore\"\n",
        "\n",
        "# @title 🖥️ STEP 2: Create Interactive Interface\n",
        "# Initialize models\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# UI Elements\n",
        "subject_dropdown = widgets.Dropdown(\n",
        "    options=[f for f in os.listdir(VECTOR_DB_PATH)\n",
        "             if f.endswith(('.faiss','.index')) and\n",
        "             os.path.exists(f\"{VECTOR_DB_PATH}/{f.split('.')[0]}_texts.pkl\")],\n",
        "    description='Subject:',\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "question_input = widgets.Textarea(\n",
        "    placeholder='Type your question here...',\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(\n",
        "    description='Ask Question',\n",
        "    button_style='primary',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# Style for UI\n",
        "style = \"\"\"\n",
        "<style>\n",
        ".qa-card {\n",
        "    border: 1px solid #e0e0e0;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    margin: 10px 0;\n",
        "    background: white;\n",
        "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "}\n",
        ".question {\n",
        "    font-weight: bold;\n",
        "    color: #202124;\n",
        "    font-size: 1.1em;\n",
        "    margin-bottom: 8px;\n",
        "}\n",
        ".answer {\n",
        "    color: #1a73e8;\n",
        "    margin: 10px 0;\n",
        "}\n",
        ".context {\n",
        "    color: #5f6368;\n",
        "    font-size: 0.9em;\n",
        "    border-top: 1px dashed #ddd;\n",
        "    padding-top: 10px;\n",
        "    margin-top: 10px;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# Display the UI\n",
        "display(HTML(style))\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h2 style='color:#202124;'>📚 Document Q&A System</h2>\"),\n",
        "    subject_dropdown,\n",
        "    widgets.HTML(\"<h3 style='margin-top:20px;'>Ask a Question</h3>\"),\n",
        "    question_input,\n",
        "    submit_button,\n",
        "    output_area\n",
        "]))\n",
        "\n",
        "# @title 🚀 STEP 3: Question Answering Logic\n",
        "def load_database(subject):\n",
        "    base_name = subject.split('.')[0]\n",
        "    try:\n",
        "        faiss_index = faiss.read_index(f\"{VECTOR_DB_PATH}/{subject}\")\n",
        "        with open(f\"{VECTOR_DB_PATH}/{base_name}_texts.pkl\", \"rb\") as f:\n",
        "            text_chunks = pickle.load(f)\n",
        "        return faiss_index, text_chunks\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading {subject}: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def on_submit_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        subject = subject_dropdown.value\n",
        "        question = question_input.value.strip()\n",
        "\n",
        "        if not question:\n",
        "            print(\"⚠️ Please enter a question\")\n",
        "            return\n",
        "\n",
        "        print(\"🔍 Searching for answer...\")\n",
        "\n",
        "        # Load database\n",
        "        faiss_index, text_chunks = load_database(subject)\n",
        "        if not faiss_index:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Search documents\n",
        "            query_vec = embedding_model.encode(question)\n",
        "            _, indices = faiss_index.search(np.array([query_vec]), k=3)\n",
        "            context = \"\\n\\n\".join([text_chunks[i] for i in indices[0] if i < len(text_chunks)])\n",
        "\n",
        "            # Generate answer\n",
        "            prompt = f\"\"\"Answer using ONLY this context:\n",
        "            {context}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Rules:\n",
        "            1. Be concise (1-2 sentences)\n",
        "            2. If unsure, say \"Not covered in materials\"\n",
        "            3. Never invent information\n",
        "\n",
        "            Answer:\"\"\"\n",
        "\n",
        "            answer = gemini_model.generate_content(prompt).text\n",
        "\n",
        "            # Display results\n",
        "            display(HTML(f\"\"\"\n",
        "            <div class='qa-card'>\n",
        "                <div class='question'>❓ {question}</div>\n",
        "                <div class='answer'>🔍 {answer}</div>\n",
        "                <details>\n",
        "                    <summary>View supporting text</summary>\n",
        "                    <div class='context'>{context[:300]}{'...' if len(context)>300 else ''}</div>\n",
        "                </details>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            display(HTML(f\"<div style='color:red;'>⚠️ Error: {str(e)}</div>\"))\n",
        "\n",
        "        question_input.value = ''  # Clear question box\n",
        "\n",
        "submit_button.on_click(on_submit_button_clicked)\n",
        "print(\"✅ System ready! Select a subject and ask questions.\")"
      ],
      "metadata": {
        "id": "dqsufoDBtXso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 📦 Install Packages\n",
        "!pip install -q google-generativeai faiss-cpu sentence-transformers ipywidgets\n",
        "print(\"✅ Packages installed!\")"
      ],
      "metadata": {
        "id": "WXpsRzs3xhGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "!mkdir -p \"/content/drive/MyDrive/Educational_PDF/vectorstore\"\n",
        "\n",
        "# Now upload your files to this folder using Colab's file browser"
      ],
      "metadata": {
        "id": "tWxWpc6qy_vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory (if it doesn't exist)\n",
        "!mkdir -p \"/content/drive/MyDrive/Educational_PDF1\"\n",
        "\n",
        "# Now upload files using Colab's file browser"
      ],
      "metadata": {
        "id": "YDWAnHPnzD5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🔧 Create New FAISS Databases\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Create directory if needed\n",
        "os.makedirs(\"/content/drive/MyDrive/Educational_PDF1\", exist_ok=True)\n",
        "\n",
        "# Sample documents - REPLACE THESE WITH YOUR ACTUAL CONTENT\n",
        "big_data_docs = [\n",
        "    \"Big data refers to extremely large datasets...\",\n",
        "    \"Hadoop is a framework for distributed processing...\",\n",
        "    \"Spark provides faster cluster computing...\",\n",
        "]\n",
        "\n",
        "computer_vision_docs = [\n",
        "    \"Computer vision enables computers to interpret images...\",\n",
        "    \"Convolutional Neural Networks (CNNs) are commonly used...\",\n",
        "    \"OpenCV is a popular computer vision library...\",\n",
        "]\n",
        "\n",
        "# Initialize model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def create_database(docs, subject_name):\n",
        "    \"\"\"Create and save FAISS database for a subject\"\"\"\n",
        "    # Generate embeddings\n",
        "    embeddings = model.encode(docs)\n",
        "\n",
        "    # Create FAISS index\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(np.array(embeddings))\n",
        "\n",
        "    # Save files\n",
        "    faiss.write_index(index, f\"/content/drive/MyDrive/Educational_PDF1/{subject_name}_faiss.index\")\n",
        "    with open(f\"/content/drive/MyDrive/Educational_PDF1/{subject_name}_texts.pkl\", \"wb\") as f:\n",
        "        pickle.dump(docs, f)\n",
        "    print(f\"✅ Created {subject_name} database at:\")\n",
        "    print(f\"/content/drive/MyDrive/Educational_PDF1/{subject_name}_faiss.index\")\n",
        "    print(f\"/content/drive/MyDrive/Educational_PDF1/{subject_name}_texts.pkl\")\n",
        "\n",
        "# Create databases\n",
        "create_database(big_data_docs, \"big_data\")\n",
        "create_database(computer_vision_docs, \"computer_vision\")"
      ],
      "metadata": {
        "id": "JZLdIjPBzIxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🔍 Verify Files Now Exist\n",
        "import os\n",
        "\n",
        "required_files = [\n",
        "    \"big_data_faiss.index\",\n",
        "    \"big_data_texts.pkl\",\n",
        "    \"computer_vision_faiss.index\",\n",
        "    \"computer_vision_texts.pkl\"\n",
        "]\n",
        "\n",
        "print(\"Final verification:\")\n",
        "all_exist = True\n",
        "for file in required_files:\n",
        "    path = f\"/content/drive/MyDrive/Educational_PDF1/{file}\"\n",
        "    exists = os.path.exists(path)\n",
        "    print(f\"  {'✅' if exists else '❌'} {file.ljust(25)}\")\n",
        "    if not exists:\n",
        "        all_exist = False\n",
        "\n",
        "if all_exist:\n",
        "    print(\"\\n🎉 All files are ready! You can now run your Q&A system.\")\n",
        "else:\n",
        "    print(\"\\n❌ Still missing files. Please try uploading again.\")"
      ],
      "metadata": {
        "id": "-NS0C-nszQZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🛠️ Create New FAISS Databases\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# 1. Create directory if needed\n",
        "os.makedirs(\"/content/drive/MyDrive/Educational_PDF1\", exist_ok=True)\n",
        "\n",
        "# 2. Add YOUR documents here (replace these examples)\n",
        "BIG_DATA_DOCS = [\n",
        "    \"Big data involves analyzing large datasets that are too complex for traditional systems\",\n",
        "    \"Hadoop is an open-source framework for distributed storage and processing of big data\",\n",
        "    \"Spark provides faster big data processing through in-memory computation\",\n",
        "    \"MapReduce is a programming model for processing large datasets in parallel\"\n",
        "]\n",
        "\n",
        "COMPUTER_VISION_DOCS = [\n",
        "    \"Computer vision enables computers to interpret and understand visual information\",\n",
        "    \"Convolutional Neural Networks (CNNs) are deep learning models for image processing\",\n",
        "    \"OpenCV is a popular library for real-time computer vision applications\",\n",
        "    \"Image segmentation partitions an image into multiple meaningful regions\"\n",
        "]\n",
        "\n",
        "# 3. Initialize embedding model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def create_database(documents, subject_name):\n",
        "    print(f\"\\n🔧 Creating {subject_name} database...\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = model.encode(documents)\n",
        "\n",
        "    # Create FAISS index\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(np.array(embeddings))\n",
        "\n",
        "    # Save files\n",
        "    faiss.write_index(index, f\"/content/drive/MyDrive/Educational_PDF1/{subject_name}_faiss.index\")\n",
        "    with open(f\"/content/drive/MyDrive/Educational_PDF1/{subject_name}_texts.pkl\", \"wb\") as f:\n",
        "        pickle.dump(documents, f)\n",
        "\n",
        "    print(f\"✅ Saved {subject_name}_faiss.index\")\n",
        "    print(f\"✅ Saved {subject_name}_texts.pkl\")\n",
        "\n",
        "# 4. Create both databases\n",
        "create_database(BIG_DATA_DOCS, \"big_data\")\n",
        "create_database(COMPUTER_VISION_DOCS, \"computer_vision\")\n",
        "\n",
        "print(\"\\n🎉 Both databases created successfully!\")"
      ],
      "metadata": {
        "id": "m-mP3m1b1EC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ✅ Verify Database Creation\n",
        "import os\n",
        "\n",
        "files_to_check = [\n",
        "    (\"big_data_faiss.index\", \"Big Data Vector Index\"),\n",
        "    (\"big_data_texts.pkl\", \"Big Data Texts\"),\n",
        "    (\"computer_vision_faiss.index\", \"Computer Vision Vector Index\"),\n",
        "    (\"computer_vision_texts.pkl\", \"Computer Vision Texts\")\n",
        "]\n",
        "\n",
        "print(\"Verifying files in /content/drive/MyDrive/Educational_PDF1/:\")\n",
        "all_ok = True\n",
        "\n",
        "for file, description in files_to_check:\n",
        "    path = f\"/content/drive/MyDrive/Educational_PDF1/{file}\"\n",
        "    exists = os.path.exists(path)\n",
        "    print(f\"{'✅' if exists else '❌'} {description.ljust(25)} - {file}\")\n",
        "    if not exists:\n",
        "        all_ok = False\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\n🌟 All files are ready! Proceed to Q&A system.\")\n",
        "else:\n",
        "    print(\"\\n❌ Some files are missing. Re-run the creation cell.\")"
      ],
      "metadata": {
        "id": "7lyn5RxC1bFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🌐 Interactive Q&A Interface\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Custom CSS styling\n",
        "css = \"\"\"\n",
        "<style>\n",
        ".qa-container {\n",
        "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "    max-width: 800px;\n",
        "    margin: 20px auto;\n",
        "    padding: 20px;\n",
        "    border-radius: 10px;\n",
        "    background: #f9f9f9;\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "}\n",
        "\n",
        ".header {\n",
        "    color: #2c3e50;\n",
        "    text-align: center;\n",
        "    margin-bottom: 25px;\n",
        "    border-bottom: 2px solid #3498db;\n",
        "    padding-bottom: 10px;\n",
        "}\n",
        "\n",
        ".subject-selector {\n",
        "    background: #ecf0f1;\n",
        "    padding: 15px;\n",
        "    border-radius: 8px;\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "\n",
        ".question-box {\n",
        "    width: 100%;\n",
        "    padding: 12px;\n",
        "    border: 2px solid #bdc3c7;\n",
        "    border-radius: 6px;\n",
        "    font-size: 16px;\n",
        "    margin-bottom: 15px;\n",
        "    transition: border 0.3s;\n",
        "}\n",
        "\n",
        ".question-box:focus {\n",
        "    border-color: #3498db;\n",
        "    outline: none;\n",
        "}\n",
        "\n",
        ".submit-btn {\n",
        "    background: #3498db;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    padding: 12px 25px;\n",
        "    border-radius: 6px;\n",
        "    cursor: pointer;\n",
        "    font-size: 16px;\n",
        "    transition: background 0.3s;\n",
        "}\n",
        "\n",
        ".submit-btn:hover {\n",
        "    background: #2980b9;\n",
        "}\n",
        "\n",
        ".answer-card {\n",
        "    background: white;\n",
        "    border-left: 4px solid #3498db;\n",
        "    padding: 15px;\n",
        "    margin-top: 20px;\n",
        "    border-radius: 6px;\n",
        "    box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
        "}\n",
        "\n",
        ".context-toggle {\n",
        "    color: #3498db;\n",
        "    cursor: pointer;\n",
        "    margin-top: 10px;\n",
        "    display: inline-block;\n",
        "}\n",
        "\n",
        ".context-text {\n",
        "    background: #f8f9fa;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "    margin-top: 10px;\n",
        "    font-size: 14px;\n",
        "    border-left: 3px solid #95a5a6;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# HTML Structure\n",
        "html = \"\"\"\n",
        "<div class=\"qa-container\">\n",
        "    <div class=\"header\">\n",
        "        <h1>📚 Document Q&A System</h1>\n",
        "        <p>Get answers from your uploaded documents</p>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"subject-selector\">\n",
        "        <h3>Step 1: Select Subject</h3>\n",
        "        <select id=\"subjectSelect\" class=\"question-box\">\n",
        "            <option value=\"big_data\">Big Data</option>\n",
        "            <option value=\"computer_vision\">Computer Vision</option>\n",
        "        </select>\n",
        "    </div>\n",
        "\n",
        "    <div>\n",
        "        <h3>Step 2: Ask a Question</h3>\n",
        "        <textarea id=\"questionInput\" class=\"question-box\"\n",
        "                  placeholder=\"Type your question here...\"></textarea>\n",
        "        <button id=\"submitBtn\" class=\"submit-btn\">Get Answer</button>\n",
        "    </div>\n",
        "\n",
        "    <div id=\"answerContainer\"></div>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "document.getElementById(\"submitBtn\").onclick = function() {\n",
        "    const question = document.getElementById(\"questionInput\").value;\n",
        "    const subject = document.getElementById(\"subjectSelect\").value;\n",
        "\n",
        "    if(!question) {\n",
        "        alert(\"Please enter a question first!\");\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    google.colab.kernel.invokeFunction('notebook.get_answer',\n",
        "        [question, subject], {});\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(css + html))"
      ],
      "metadata": {
        "id": "lkla0sD61fZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🧠 Q&A Backend Logic\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Initialize models\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Database paths\n",
        "VECTOR_DB_PATH = \"/content/drive/MyDrive/Educational_PDF1\"\n",
        "\n",
        "def get_answer(question, subject):\n",
        "    try:\n",
        "        # Load database\n",
        "        faiss_index = faiss.read_index(f\"{VECTOR_DB_PATH}/{subject}_faiss.index\")\n",
        "        with open(f\"{VECTOR_DB_PATH}/{subject}_texts.pkl\", \"rb\") as f:\n",
        "            text_chunks = pickle.load(f)\n",
        "\n",
        "        # Search documents\n",
        "        query_vec = embedding_model.encode(question)\n",
        "        _, indices = faiss_index.search(np.array([query_vec]), k=3)\n",
        "        context = \"\\n\\n\".join([text_chunks[i] for i in indices[0] if i < len(text_chunks)])\n",
        "\n",
        "        # Generate answer\n",
        "        prompt = f\"\"\"Answer using ONLY this context:\n",
        "        {context}\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Rules:\n",
        "        1. Be concise (1-2 sentences)\n",
        "        2. If unsure, say \"Not covered in materials\"\n",
        "        3. Never invent information\n",
        "\n",
        "        Answer:\"\"\"\n",
        "\n",
        "        answer = gemini_model.generate_content(prompt).text\n",
        "\n",
        "        # Format output\n",
        "        display(HTML(f\"\"\"\n",
        "        <div class=\"answer-card\">\n",
        "            <div style=\"font-weight:bold;\">❓ Question: {question}</div>\n",
        "            <div style=\"color:#2c3e50; margin:10px 0;\">🔍 Answer: {answer}</div>\n",
        "            <div class=\"context-toggle\" onclick=\"this.nextElementSibling.style.display =\n",
        "                this.nextElementSibling.style.display === 'none' ? 'block' : 'none'\">\n",
        "                ▼ Show supporting context\n",
        "            </div>\n",
        "            <div class=\"context-text\" style=\"display:none;\">\n",
        "                {context[:500]}{'...' if len(context)>500 else ''}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"color:red; padding:10px; background:#ffeeee; border-radius:5px;\">\n",
        "            ⚠️ Error: {str(e)}\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "# Register the function\n",
        "from google.colab import output\n",
        "output.register_callback('notebook.get_answer', get_answer)"
      ],
      "metadata": {
        "id": "NijIXpub1kIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "os0uQR8W1rxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}